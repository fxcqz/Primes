import os
import numpy
import logging
from primes.utils.custom_complex import CustomComplex


logger = logging.getLogger(__name__)

class Generator(object):
    """Super class for all Generators  used within this  application. This class
    provides utility functions for  generators used  when  interacting  with the
    cache, as well as setting up familiar attributes across all Generators.

    Attributes:
        minimum (int): The lower constraining value.
        maximum (int): The upper constraining value.
        path (string): Location of the generators data when saved  in the cache,
                       this will be unique for each unique Generator.
        datatype (type): The type of the data to be handled/generated.
        runnable (bool): Whether the generator is able  to accurately generate a
                         dataset. This  is  typically dictated   by  the imputed
                         arguments.
        threshold (int): The maximum number of elements that can be missing from
                         the cache before reverting to a full  regeneration.  If
                         the   number  of missing  elements  is  lower than  the 
                         threshold, the class will use some form  of check, such
                         as a primality check in the case of prime generation.
        data (list): A list of   elements  of  type `datatype'  which  have been
                     generated by the class's `generate' function.
    
    Keyword Arguments:
        minimum -- The minimum value to be used in the dataset (default: 0)
        maximum -- The maximum value to be used in the dataset (default: 1)
    """
    def __init__(self, minimum=0, maximum=1):
        self.minimum = minimum
        self.maximum = maximum
        self.path = "primes/generator/data/"
        self.datatype = int
        self.runnable = True
        # maximum number of elements missing from cache to do full generation
        self.threshold = 100
        self.data = []

    def generate(self):
        """(Stub) The function which generates the  dataset. This is implemented
        uniquely by sub-classes of this super class.

        The process is however similar throughout all Generators. The class will
        initially attempt to read pre-existing data from the cache. If  the full
        amount of data (or more) exists in the cache, then it is read and stored
        in the `data' instance variable and no generation is necessary. 
        If the amount of data missing from the cache is lower than the threshold
        then we  shall  test all of  the  missing  values   against a determiner
        function.  These  new values will be  imputed  and sorted into the final
        dataset.
        If the amount of missing data exceeds the  threshold, or no  data exists
        in the cache, the  program  will typically revert to an  algorithm or an
        optimised routine to more efficiently generate larger amounts of data.
        """
        pass

    def get_data(self):
        """Return the data attribute"""
        return self.data

    def set_specifics(self, data):
        """(Stub) Some generators require additional data to function correctly.
        This function is used  to set these  additional  values on an individual
        basis before running the generation.
        """
        pass

    # cache read

    def data_files_from_dir(self):
        """Return a list of data files from a directory.

        This function uses  the `path'  instance  variable for  the directory to
        check.
        """
        return filter(lambda x: ".dat" in x, list(os.walk(self.path))[0][2])

    def read_cache(self):
        """Reads data pertinent to the specific (invoking)  generator from that
        generator's specific cache directory.

        Returns:
            A list of data read from the cache if any exists, such that all
            elements e satisfy: minimum <= e <= maximum.
            An empty list if no data is found in the cache.
        """
        # TODO: This may  be optimised  for better memory  efficiency, either by
        #       reading one file at a time and verifying the contents, or simply
        #       stopping a file read if the data range required by the generator
        #       has been satisfied.
        if os.path.exists(os.path.dirname(self.path)):
            files = self.data_files_from_dir()
            logger.info(files)
            data = None
            # `Total Data': All data from multiple files is stored here.
            tdata = []
            logger.info("Checking cache")
            if any(files):
                for f_ in files:
                    with open(self.path + f_, 'r') as f:
                        # read the contents of each data file in the cache.
                        # data files are comma separated.
                        data = numpy.loadtxt(f, delimiter=',', dtype=self.datatype)
                        logger.info("Finding pertinent data (%s - %s)", \
                            self.minimum, self.maximum)
                        # add the data to the total data
                        tdata += list(data)
                        logger.info("Data length %s", str(len(data)))
            if tdata:
                logger.info("Removing duplicates")
                # set will remove duplicate values from the list.
                tdata = list(set(tdata))
                # remove values lesser or greater than the minimum or maximum
                # respectively.
                tdata = filter(lambda x: self.minimum <= x <= self.maximum, \
                    tdata)
                logger.info("Sorting data")
                # more often than not, the visualisations require the data to be
                # sorted, so better safe than sorry for all cases.
                tdata.sort()
            else:
                logger.info("No data found in cache")
            return numpy.array(tdata)
        return []

    def complex_range(self, minimum, maximum):
        """Utility function for constructing a range of complex numbers between
        two values, minimum and maximum.

        Arguments:
            minimum -- the lower value in the range
            maximum -- the upper value in the range

        Returns:
            A list of complex numbers constituting a range of concurrent values.
        """
        if not isinstance(minimum, complex) or not isinstance(maximum, complex):
            return []
        zs = []
        for i in range(numpy.real(minimum), numpy.real(maximum)):
            for j in range(numpy.imag(minimum), numpy.imag(maximum)):
                zs.append(CustomComplex(i, j))
        return zs

    def not_in_cache(self):
        """Find all  values  missing from  a cache  read based  on  the range of
        values defined  by the  lower  and  upper  limits  of  the minimum   and 
        maximum instance variables.

        Returns:
            A 2d list of values missing from  the cache. The first  list will be
            the values  missing from the  start of the list  and the second list
            will  be the  values  missing from  the  end of the  list. Note that
            interim values are not checked.
        """
        ret = None
        if len(self.data) != 0:
            # the ranges change depending on the type of the data
            if self.datatype == complex:
                ret = self.complex_range(self.minimum, self.data[0]), \
                      self.complex_range(self.data[-1] + complex(1, 1), 
                                         self.maximum + complex(1, 1))
            else:
                ret = range(self.minimum, min(self.data)), \
                      range(max(self.data) + 1, self.maximum + 1)
        if ret:
            if len(ret[0]) + len(ret[1]) > self.threshold:
                # not interested in missing data if the length of the data
                # missing exceeds the threshold.
                ret = None
        return ret

    # cache write
    # TODO: this can be improved to not cache duplicate data
    #       (file rotation/size cap etc)

    def next_filename(self, path):
        """Determine the name of the next file in a cache directory.

        File names are simply: 1.dat, 2.dat, etc.
        If no directory exists then the function will create one.

        Arguments:
            path -- the name of the path to check

        Returns:
            The name of the next file to be created in the directory.
        """
        try:
            if os.path.exists(os.path.dirname(path)):
                logger.info("Retrieving path info")
                _, _, files = os.walk(path).next()
                return str(len(files) + 1) + ".dat"
            else:
                logger.warning("No path available, creating one")
                os.makedirs(os.path.dirname(path))
        except StopIteration:
            pass
        return "1.dat"

    def to_file(self):
        """Writes the data stored  in the `data' instance  variable to a file in
        the cache. If no data exists, the it will attempt to generate some.
        """
        if not any(self.data):
            self.generate()
        try:
            filename = self.next_filename(self.path)
            if not os.path.exists(os.path.dirname(self.path)):
                # just in case no path exists to save to
                os.makedirs(os.path.dirname(self.path))
            with open(self.path + filename, 'w') as f:
                logger.info("Writing data to file %s", self.path + filename)
                # write data as comma separated values
                f.write(','.join([str(n) for n in self.data]))
        except IOError:
            logger.error("Failed to write data", exc_info=True)
